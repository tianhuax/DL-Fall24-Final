{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we do the experiments for quantizing KV vectors and LLM models using the framework from QUAROT (https://github.com/spcl/QuaRot/tree/main).\n",
        "\n",
        "We do some modification to the Quarot repository and store our version here: https://github.com/tianhua2/my_quarot.git\n",
        "\n",
        "We also edit the llama code in huggingface to add KV vector quantization and eviction codes. We store it as our own package here: https://github.com/tianhua2/my_huggingface.git\n",
        "The KV vector eviction codes is based on H2O (https://github.com/FMInference/H2O) with some modification."
      ],
      "metadata": {
        "id": "TJKMkpiV8KZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment Settings."
      ],
      "metadata": {
        "id": "NBAMNfmo65DY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al8-0leG6yzj"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login --token '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'\n",
        "!rm -rf my_huggingface\n",
        "!git clone https://github.com/tianhua2/my_huggingface.git\n",
        "%cd /content/my_huggingface\n",
        "!pip install .\n",
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
        "%cd lm-evaluation-harness\n",
        "!pip install .\n",
        "%cd /content/\n",
        "\n",
        "%cd /content/\n",
        "!rm -rf my_quarot\n",
        "!git clone https://github.com/tianhua2/my_quarot.git\n",
        "%cd /content/my_quarot\n",
        "!pip install .\n",
        "%cd /content/\n",
        "\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install accelerate -U\n",
        "!pip install --upgrade pyarrow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from bokeh.io import show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.layouts import column\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.palettes import Category20# select a palette\n",
        "import itertools\n",
        "output_notebook()\n",
        "\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import Trainer\n",
        "import numpy as np\n",
        "\n",
        "!cp /content/drive/MyDrive/kv_cache/llama2_7b_w4a4 /content/llama2_7b_w4a4\n",
        "\n",
        "%cd /content/my_quarot/fake_quant/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama2-7b fp16"
      ],
      "metadata": {
        "id": "lLWaN2zl7N_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/my_quarot/fake_quant/\n",
        "!python main.py --model meta-llama/Llama-2-7b-hf --a_bits 16 --v_bits 16 --k_bits 16 --w_bits 16 --bsz 4 --w_clip \\\n",
        "--lm_eval --lm_eval_batch_size 16 --tasks \"piqa\" \"arc_easy\" \"arc_challenge\" \"winogrande\" --eval_dataset 'c4'"
      ],
      "metadata": {
        "id": "AG4u17tN69Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama2-7b W8A8KV4"
      ],
      "metadata": {
        "id": "Ku_Lezlw7Qw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/my_quarot/fake_quant/\n",
        "!python main.py --model meta-llama/Llama-2-7b-hf --rotate --a_bits 8 --v_bits 16 --k_bits 16 --w_bits 8 --bsz 1 --w_clip \\\n",
        "--DYNQ --KRON --KV_BITS1 4 --KV_BITS2 4 --KV_BITS3 4 --KV_BITS4 4 --heavy_budget_ratio1 0.15 --heavy_budget_ratio2 0.3 --heavy_budget_ratio3 0.5\\\n",
        "--TH_H 1e-3 --TH_L 1e-2 --TH_H2 1e-3 --TH_L2 1e-2 --TH_H3 1e-3 --TH_L3 1e-2 --TH_H4 1e-3 --TH_L4 1e-2\\\n",
        "--H2O --heavy_budget_ratio 0.3 --recent_budget_ratio 0.1 --score_coeff 0 --CACHE_SIZE 1024\\\n",
        "--lm_eval --lm_eval_batch_size 16 --tasks \"piqa\" \"arc_easy\" \"arc_challenge\" \"winogrande\" \"lamabada\""
      ],
      "metadata": {
        "id": "QtQSntBX7RMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama2-13b fp16"
      ],
      "metadata": {
        "id": "oUZuZ8mW7g9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/my_quarot/fake_quant/\n",
        "!python main.py --model meta-llama/Llama-2-13b-hf --a_bits 16 --v_bits 16 --k_bits 16 --w_bits 16 --bsz 1 --w_clip \\\n",
        "--lm_eval --lm_eval_batch_size 16 --tasks \"piqa\" \"arc_easy\" \"arc_challenge\" \"winogrande\""
      ],
      "metadata": {
        "id": "F2imRlqr7gWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama2-13b W8A8KV4"
      ],
      "metadata": {
        "id": "52F4V6DA7nUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/my_quarot/fake_quant/\n",
        "!python main.py --model meta-llama/Llama-2-13b-hf --rotate --a_bits 8 --v_bits 16 --k_bits 16 --w_bits 8 --bsz 1 --w_clip \\\n",
        "--DYNQ --KRON --KV_BITS1 4 --KV_BITS2 4 --KV_BITS3 4 --KV_BITS4 4 --heavy_budget_ratio1 0.15 --heavy_budget_ratio2 0.3 --heavy_budget_ratio3 0.5\\\n",
        "--TH_H 1e-3 --TH_L 1e-2 --TH_H2 1e-3 --TH_L2 1e-2 --TH_H3 1e-3 --TH_L3 1e-2 --TH_H4 1e-3 --TH_L4 1e-2\\\n",
        "--H2O --heavy_budget_ratio 0.3 --recent_budget_ratio 0.1 --score_coeff 0 --CACHE_SIZE 1024\\\n",
        "--lm_eval --lm_eval_batch_size 16 --tasks \"piqa\" \"arc_easy\" \"arc_challenge\" \"winogrande\" \"lamabada\""
      ],
      "metadata": {
        "id": "uAXYPqQm7jmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama3-8b fp16"
      ],
      "metadata": {
        "id": "hVMacaGl7wNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/my_quarot/fake_quant/\n",
        "!python main.py --model meta-llama/Meta-Llama-3-8B --a_bits 16 --v_bits 16 --k_bits 16 --w_bits 16 --bsz 1 --w_clip \\\n",
        "--lm_eval --lm_eval_batch_size 16 --tasks \"piqa\" \"arc_easy\" \"arc_challenge\" \"winogrande\""
      ],
      "metadata": {
        "id": "wATXDsyy7vyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama3-8b W8A8KV4"
      ],
      "metadata": {
        "id": "-WLUskoN705j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/my_quarot/fake_quant/\n",
        "!python main.py --model meta-llama/Meta-Llama-3-8B --rotate --a_bits 8 --v_bits 16 --k_bits 16 --w_bits 4 --bsz 1 --w_clip\\\n",
        "--DYNQ --KRON --KV_BITS1 4 --KV_BITS2 4 --KV_BITS3 4 --KV_BITS4 4 --heavy_budget_ratio1 0.03 --heavy_budget_ratio2 0.15 --heavy_budget_ratio3 0.8\\\n",
        "--TH_H 1e-3 --TH_L 1e-2 \\\n",
        "--H2O --heavy_budget_ratio 0.3 --recent_budget_ratio 0.1 --score_coeff 0 --CACHE_SIZE 256\\\n",
        "--lm_eval --lm_eval_batch_size 16 --tasks \"piqa\" \"arc_easy\" \"arc_challenge\" \"winogrande\" \\\n",
        "--load_qmodel_path \"/content/llama3_8b_w4\""
      ],
      "metadata": {
        "id": "Bb9Yap7z7ybd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}